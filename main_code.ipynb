{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "w7lShx07oTIS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "seat_df = pd.read_csv('/content/drive/MyDrive/seat.csv')\n",
        "lounge_df = pd.read_csv('/content/drive/MyDrive/lounge.csv')\n",
        "airline_df = pd.read_csv('/content/drive/MyDrive/airline.csv')\n",
        "airport_df = pd.read_csv('/content/drive/MyDrive/airport.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Please run this code before running for all categories one\n",
        "\n",
        "\n",
        "###### This is single category test i did for figuring things out"
      ],
      "metadata": {
        "id": "1gTCZawBAwim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "categories = [\"overall\", \"queuing\", \"seat_comfort\", \"cabin\", \"staff\", \"value_for_money\", \"food\", \"shopping\", \"wifi\", \"hygiene\", \"entertainment\"]\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "\n",
        "    phrases_to_capture = [\n",
        "        'not comfortable', 'not clean', 'not satisfied', 'not friendly',\n",
        "        'very comfortable', 'excellent service', 'highly recommend', 'great experience',\n",
        "        'poor quality', 'bad experience', 'disappointed'\n",
        "    ]\n",
        "\n",
        "\n",
        "    for phrase in phrases_to_capture:\n",
        "        text = text.replace(phrase, phrase.replace(\" \", \"_\"))\n",
        "\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
        "    tokens = text.split()\n",
        "\n",
        "\n",
        "    new_tokens = []\n",
        "    for token in tokens:\n",
        "        if token not in stop_words:\n",
        "            new_tokens.append(token)\n",
        "\n",
        "    return new_tokens\n",
        "\n"
      ],
      "metadata": {
        "id": "SPImBg89EpLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mappings = {\n",
        "    'lounge': {\n",
        "        'overall_rating': 'overall',\n",
        "        'comfort_rating': 'seat_comfort',\n",
        "        'staff_service_rating': 'staff',\n",
        "        'bar_beverages_rating': 'food',\n",
        "        'wifi_connectivity_rating': 'wifi',\n",
        "        'cleanliness_rating': 'hygiene',\n",
        "    },\n",
        "    'airport': {\n",
        "        'overall_rating': 'overall',\n",
        "        'queuing_rating': 'queuing',\n",
        "        'terminal_seating_rating': 'seat_comfort',\n",
        "        'airport_staff_rating': 'staff',\n",
        "        'food_beverages_rating': 'food',\n",
        "        'airport_shopping_rating': 'shopping',\n",
        "        'wifi_connectivity_rating': 'wifi',\n",
        "        'terminal_cleanliness_rating': 'hygiene',\n",
        "    },\n",
        "    'airline': {\n",
        "        'overall_rating': 'overall',\n",
        "        'seat_comfort_rating': 'seat_comfort',\n",
        "        'cabin_staff_rating': 'staff',\n",
        "        'value_money_rating': 'value_for_money',\n",
        "        'food_beverages_rating': 'food',\n",
        "        'wifi_connectivity_rating': 'wifi',\n",
        "        'inflight_entertainment_rating': 'entertainment'\n",
        "    },\n",
        "    'seat': {\n",
        "        'overall_rating': 'overall',\n",
        "        'seat_legroom_rating': 'seat_comfort',\n",
        "        'viewing_tv_rating': 'entertainment'\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "nQuJJ4-HGTd4"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fill_missing_values(dataframe, relevant_columns):\n",
        "    for column in relevant_columns:\n",
        "        dataframe[column] = dataframe[column].fillna(\"Unknown\")\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "lounge_df_filled = fill_missing_values(lounge_df, ['comfort_rating', 'overall_rating'])\n",
        "airport_df_filled = fill_missing_values(airport_df, ['terminal_seating_rating', 'overall_rating'])\n",
        "airline_df_filled = fill_missing_values(airline_df, ['seat_comfort_rating', 'overall_rating'])\n",
        "seat_df_filled = fill_missing_values(seat_df, ['seat_legroom_rating', 'overall_rating'])\n",
        "\n",
        "\n",
        "print(\"Filled Lounge Dataset Rows:\", lounge_df_filled.shape[0])\n",
        "print(\"Filled Airport Dataset Rows:\", airport_df_filled.shape[0])\n",
        "print(\"Filled Airline Dataset Rows:\", airline_df_filled.shape[0])\n",
        "print(\"Filled Seat Dataset Rows:\", seat_df_filled.shape[0])\n"
      ],
      "metadata": {
        "id": "He6xgOghGYY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word_counts = {cat: defaultdict(Counter) for cat in categories}\n",
        "rating_counts = {cat: Counter() for cat in categories}\n",
        "\n",
        "def process_reviews_all_categories(dataframe, text_column, mapping):\n",
        "    for idx, row in dataframe.iterrows():\n",
        "        for actual_col, category in mapping.items():\n",
        "            if row[actual_col] != \"Unknown\":\n",
        "                try:\n",
        "                    rating = int(row[actual_col])\n",
        "                    if rating < 1 or rating > 5:\n",
        "                        continue\n",
        "                    rating_counts[category][rating] += 1\n",
        "                    words = tokenize(row[text_column])\n",
        "                    for word in words:\n",
        "                        word_counts[category][word][rating] += 1\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "\n",
        "process_reviews_all_categories(lounge_df_filled, 'content', mappings['lounge'])\n",
        "process_reviews_all_categories(airport_df_filled, 'content', mappings['airport'])\n",
        "process_reviews_all_categories(airline_df_filled, 'content', mappings['airline'])\n",
        "process_reviews_all_categories(seat_df_filled, 'content', mappings['seat'])\n",
        "\n",
        "\n",
        "print(\"Word Counts for 'overall' category after processing:\")\n",
        "print(word_counts['overall'])\n",
        "\n",
        "print(\"\\nRating Counts for 'overall' category after processing:\")\n",
        "print(rating_counts['overall'])\n"
      ],
      "metadata": {
        "id": "_v-RcQuJGaYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prior_probs = {cat: {} for cat in categories}\n",
        "for cat in categories:\n",
        "    total_reviews = sum(rating_counts[cat].values())\n",
        "    for rating, count in rating_counts[cat].items():\n",
        "        prior_probs[cat][rating] = count / total_reviews\n",
        "\n",
        "print(\"Prior probabilities for 'overall' category:\")\n",
        "print(prior_probs['overall'])\n"
      ],
      "metadata": {
        "id": "uBpibikIGcrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_likelihood(word, rating, category):\n",
        "    total_word_count = sum(word_counts[category][word].values())\n",
        "    word_count_for_rating = word_counts[category][word][rating]\n",
        "\n",
        "    if word_count_for_rating == 0:\n",
        "        total_reviews_in_category = sum(rating_counts[category].values())\n",
        "        return 1 / (total_reviews_in_category + 1e-6)\n",
        "    total_reviews_in_category = sum(rating_counts[category].values())\n",
        "    normalized_likelihood = word_count_for_rating / total_word_count\n",
        "\n",
        "    return normalized_likelihood\n",
        "\n",
        "\n",
        "test_phrase = \"not_comfortable\"\n",
        "test_rating = 1\n",
        "test_category = \"seat_comfort\"\n",
        "\n",
        "likelihood = compute_likelihood(test_phrase, test_rating, test_category)\n",
        "print(f\"Likelihood of phrase '{test_phrase}' for rating {test_rating} in '{test_category}': {likelihood}\")\n"
      ],
      "metadata": {
        "id": "xQ5dTGMkGpC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR ALL CATEGORIES (PLEASE RUN PREVIOUS CODES BEFORE RUNNING THIS)"
      ],
      "metadata": {
        "id": "aPzQp8cTAnyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------"
      ],
      "metadata": {
        "id": "b6Qsxi_qJEv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "\n",
        "    phrases_to_capture = [\n",
        "        'not comfortable', 'not clean', 'not satisfied', 'not friendly',\n",
        "        'uncomfortable', 'very comfortable', 'excellent service', 'highly recommend',\n",
        "        'great experience', 'poor quality', 'bad experience', 'disappointed', 'good'\n",
        "    ]\n",
        "\n",
        "\n",
        "    for phrase in phrases_to_capture:\n",
        "        text = text.replace(phrase, phrase.replace(\" \", \"_\"))\n",
        "\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
        "\n",
        "\n",
        "    parts_but = re.split(r'\\s+but\\s+', text)\n",
        "\n",
        "\n",
        "    if len(parts_but) > 1:\n",
        "\n",
        "        before_but = [token for token in parts_but[0].split() if token not in stop_words]\n",
        "        after_but = [token for token in parts_but[1].split() if token not in stop_words]\n",
        "        return before_but, after_but\n",
        "\n",
        "\n",
        "    parts_and = re.split(r'\\s+and\\s+', text)\n",
        "    combined_tokens = []\n",
        "    for part in parts_and:\n",
        "        part_tokens = [token for token in part.split() if token not in stop_words]\n",
        "        combined_tokens.extend(part_tokens)\n",
        "\n",
        "    return combined_tokens\n"
      ],
      "metadata": {
        "id": "oetS7vXwHHGI"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mappings = {\n",
        "    'lounge': {\n",
        "        'overall_rating': 'overall',\n",
        "        'comfort_rating': 'seat_comfort',\n",
        "        'staff_service_rating': 'staff',\n",
        "        'bar_beverages_rating': 'food',\n",
        "        'wifi_connectivity_rating': 'wifi',\n",
        "        'cleanliness_rating': 'hygiene',\n",
        "    },\n",
        "    'airport': {\n",
        "        'overall_rating': 'overall',\n",
        "        'queuing_rating': 'queuing',\n",
        "        'terminal_seating_rating': 'seat_comfort',\n",
        "        'airport_staff_rating': 'staff',\n",
        "        'food_beverages_rating': 'food',\n",
        "        'airport_shopping_rating': 'shopping',\n",
        "        'wifi_connectivity_rating': 'wifi',\n",
        "        'terminal_cleanliness_rating': 'hygiene',\n",
        "    },\n",
        "    'airline': {\n",
        "        'overall_rating': 'overall',\n",
        "        'seat_comfort_rating': 'seat_comfort',\n",
        "        'cabin_staff_rating': 'staff',\n",
        "        'value_money_rating': 'value_for_money',\n",
        "        'food_beverages_rating': 'food',\n",
        "        'wifi_connectivity_rating': 'wifi',\n",
        "        'inflight_entertainment_rating': 'entertainment'\n",
        "    },\n",
        "    'seat': {\n",
        "        'overall_rating': 'overall',\n",
        "        'seat_legroom_rating': 'seat_comfort',\n",
        "        'viewing_tv_rating': 'entertainment'\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "xcLePHeuJICj"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fill_missing_values(dataframe):\n",
        "    for column in dataframe.columns:\n",
        "        if dataframe[column].isnull().any():\n",
        "            dataframe[column] = dataframe[column].fillna(\"Unknown\")\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "lounge_df_filled = fill_missing_values(lounge_df)\n",
        "airport_df_filled = fill_missing_values(airport_df)\n",
        "airline_df_filled = fill_missing_values(airline_df)\n",
        "seat_df_filled = fill_missing_values(seat_df)\n",
        "\n",
        "\n",
        "print(\"Filled Lounge Dataset Rows:\", lounge_df_filled.shape[0])\n",
        "print(\"Filled Airport Dataset Rows:\", airport_df_filled.shape[0])\n",
        "print(\"Filled Airline Dataset Rows:\", airline_df_filled.shape[0])\n",
        "print(\"Filled Seat Dataset Rows:\", seat_df_filled.shape[0])\n"
      ],
      "metadata": {
        "id": "TGj_ZEywJK8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "jAk2am6gJZGl"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_reviews_all_categories(dataframe, text_column, mapping):\n",
        "    for idx, row in dataframe.iterrows():\n",
        "        for actual_col, category in mapping.items():\n",
        "            if row[actual_col] != \"Unknown\":\n",
        "                try:\n",
        "                    rating = int(row[actual_col])\n",
        "                    if rating < 1 or rating > 5:\n",
        "                        continue\n",
        "                    rating_counts[category][rating] += 1\n",
        "\n",
        "\n",
        "                    tokens = tokenize(row[text_column])\n",
        "\n",
        "\n",
        "                    if isinstance(tokens, tuple):\n",
        "                        before_but, after_but = tokens\n",
        "\n",
        "                        for word in before_but:\n",
        "                            word_counts[category][word][rating] += 1\n",
        "                        for word in after_but:\n",
        "                            word_counts[category][word][rating] += 2\n",
        "                    else:\n",
        "\n",
        "                        for word in tokens:\n",
        "                            word_counts[category][word][rating] += 1\n",
        "                except ValueError:\n",
        "                    pass\n"
      ],
      "metadata": {
        "id": "MNqJ24Q2JNkx"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prior_probs = {cat: {} for cat in categories}\n",
        "for cat in categories:\n",
        "    total_reviews = sum(rating_counts[cat].values())\n",
        "    for rating, count in rating_counts[cat].items():\n",
        "        prior_probs[cat][rating] = count / total_reviews if total_reviews > 0 else 0\n",
        "\n",
        "\n",
        "print(\"Prior probabilities for 'overall' category:\")\n",
        "print(prior_probs['overall'])\n"
      ],
      "metadata": {
        "id": "s_7FhRhfJPkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_likelihood(word, rating, category):\n",
        "    if word not in word_counts[category]:\n",
        "        return 1e-6\n",
        "\n",
        "    total_word_count = sum(word_counts[category][word].values())\n",
        "    word_count_for_rating = word_counts[category][word][rating]\n",
        "\n",
        "    if total_word_count == 0:\n",
        "        return 1e-6\n",
        "\n",
        "\n",
        "    normalized_likelihood = word_count_for_rating / total_word_count\n",
        "    return normalized_likelihood if normalized_likelihood > 0 else 1e-6\n"
      ],
      "metadata": {
        "id": "0wVWc8nvJoRm"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "7cQc-rsEKUqF"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_rating(review_text, category):\n",
        "    tokens = tokenize(review_text)\n",
        "\n",
        "    best_rating = None\n",
        "    max_log_posterior = -float('inf')\n",
        "\n",
        "    for rating in prior_probs[category]:\n",
        "        log_prior = math.log(prior_probs[category][rating]) if prior_probs[category][rating] > 0 else -float('inf')\n",
        "        log_likelihood = 0\n",
        "\n",
        "\n",
        "        if isinstance(tokens, tuple):\n",
        "            before_but, after_but = tokens\n",
        "\n",
        "            for word in before_but:\n",
        "                likelihood = compute_likelihood(word, rating, category)\n",
        "                if likelihood > 0:\n",
        "                    log_likelihood += math.log(likelihood)\n",
        "            for word in after_but:\n",
        "                likelihood = compute_likelihood(word, rating, category)\n",
        "                if likelihood > 0:\n",
        "                    log_likelihood += 2 * math.log(likelihood)\n",
        "        else:\n",
        "\n",
        "            for word in tokens:\n",
        "                likelihood = compute_likelihood(word, rating, category)\n",
        "                if likelihood > 0:\n",
        "                    log_likelihood += math.log(likelihood)\n",
        "\n",
        "\n",
        "        log_posterior = log_prior + log_likelihood\n",
        "\n",
        "        if log_posterior > max_log_posterior:\n",
        "            max_log_posterior = log_posterior\n",
        "            best_rating = rating\n",
        "\n",
        "    return best_rating\n"
      ],
      "metadata": {
        "id": "BOaz11oNJqiD"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_ratings_for_all_categories(review_text):\n",
        "    predicted_ratings = {}\n",
        "    sentiment_score = 0\n",
        "    total_weight = 0\n",
        "\n",
        "\n",
        "    for category in categories:\n",
        "        best_rating = predict_rating(review_text, category)\n",
        "        predicted_ratings[category] = best_rating\n",
        "\n",
        "\n",
        "        if best_rating is not None:\n",
        "            if best_rating >= 4:\n",
        "                sentiment_score += 1 * best_rating\n",
        "            elif best_rating <= 2:\n",
        "                sentiment_score -= 1 * (3 - best_rating)\n",
        "            total_weight += 1\n",
        "\n",
        "\n",
        "    if total_weight > 0:\n",
        "        overall_score = sentiment_score / total_weight\n",
        "\n",
        "\n",
        "        if overall_score >= 4.5:\n",
        "            predicted_ratings['overall'] = 5\n",
        "        elif overall_score >= 3.5:\n",
        "            predicted_ratings['overall'] = 4\n",
        "        elif overall_score >= 2.5:\n",
        "            predicted_ratings['overall'] = 3\n",
        "        elif overall_score >= 1.5:\n",
        "            predicted_ratings['overall'] = 2\n",
        "        else:\n",
        "            predicted_ratings['overall'] = 1\n",
        "    else:\n",
        "        predicted_ratings['overall'] = 3\n",
        "\n",
        "    return predicted_ratings\n",
        "\n",
        "\n",
        "mixed_reviews = [\"The food was poor quality, and the wifi didn't work at all. The staff was not friendly.\"]\n",
        "\n",
        "\n",
        "for review in mixed_reviews:\n",
        "    predicted_ratings = predict_ratings_for_all_categories(review)\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Predicted Ratings: {predicted_ratings}\\n\")\n"
      ],
      "metadata": {
        "id": "VkOhUyEpKROC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJuPw8xtQt2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}